# üì∞ News Events Data Quality Pipeline

## üìò Overview

This project automates the **data quality and preprocessing pipeline** for News Events data in JSONL format.
It ingests raw files, cleans and validates them, generates Data Quality (DQ) metrics, and uploads processed data into **Amazon Redshift** for analysis in BI tools like Tableau.

Built using **Streamlit** for interactivity and **AWS services** for backend orchestration, it ensures end-to-end automation, DQ governance, and alerting.

---

## ‚öôÔ∏è Core Workflow

**1Ô∏è‚É£ Data Upload & Ingestion**

* Users upload JSONL files via the Streamlit UI.
* Files are stored in **Amazon S3 (raw bucket)** and parsed into:

  * `df_data`: Event details
  * `df_included`: Metadata (company, author, source)

**2Ô∏è‚É£ Preprocessing**

* Handles missing values and duplicates
* Cleans and standardizes date columns
* Detects outliers using the IQR method
* Removes long text fields incompatible with Redshift

**3Ô∏è‚É£ Data Profiling**

* Displays schema info, null counts, and unique values
* Generates category and confidence distributions
* Compares data before and after cleaning

**4Ô∏è‚É£ Redshift Integration**

* Automatically creates tables:

  * `news_events_data`
  * `news_events_included`
  * `dq_summary`
* Inserts cleaned data into Redshift
* Creates a BI-ready view `news_events_view`

**5Ô∏è‚É£ Data Quality & Alerts**

* Calculates DQ metrics: Completeness, Accuracy, Uniqueness, Consistency, Timeliness
* Stores metrics in Redshift
* Sends **SNS alerts** when DQ score < threshold

---

## ‚òÅÔ∏è AWS Architecture

```
User Upload
    ‚Üì
Amazon S3 (Raw Data)
    ‚Üì
AWS Lambda (Validation & Transformation)
    ‚Üì
Amazon Redshift (Tables & DQ Metrics)
    ‚Üì
Streamlit Dashboard (EDA & Monitoring)
    ‚Üì
AWS SNS (DQ Alerts)
```

---

## üìä Key Outputs

* Cleaned CSVs:

  * `cleaned_df_data.csv`
  * `cleaned_df_included.csv`
* Redshift Tables:

  * `news_events_data`
  * `news_events_included`
  * `dq_summary`
* Alerts: Real-time SNS notifications

---

## üß∞ Tech Stack

**Frontend:** Streamlit
**Processing:** Pandas, NumPy, Matplotlib, Seaborn
**Cloud:** AWS S3, Redshift, Lambda, SNS, Secrets Manager
**Integration:** psycopg2, boto3

---

## üöÄ Benefits

* End-to-end automated DQ pipeline
* Real-time data validation & alerting
* Scalable and secure AWS integration
* Tableau-ready data for analytics

---

## üìÅ Project Structure

```
news-data-quality-project/
‚îÇ
‚îú‚îÄ‚îÄ app.py                        # Streamlit App
‚îú‚îÄ‚îÄ aws_lambda_trigger.py         # AWS Lambda trigger logic
‚îú‚îÄ‚îÄ redshift_sql_query.py         # Redshift schema setup
‚îú‚îÄ‚îÄ Datasets-2025-08-08/          # Sample datasets
‚îú‚îÄ‚îÄ News_Events_Data_Quality_Analysis_Pipeline.docx
‚îú‚îÄ‚îÄ Sample_Report.pdf
‚îî‚îÄ‚îÄ README.md                     # Project documentation
```

---
